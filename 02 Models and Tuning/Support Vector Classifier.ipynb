{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Support Vector Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setting up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score, precision_score, fbeta_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../Data/train.csv\")\n",
    "y_train = df_train[[\"attrition_flag\"]]\n",
    "x_train = df_train.drop(\"attrition_flag\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Running base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_evaluate_model(svc):\n",
    "    scale_features = x_train.drop(\"gender\", axis=1).columns\n",
    "    scaler = ColumnTransformer(transformers=[ ('scaler', MinMaxScaler(), scale_features) ], remainder='passthrough')\n",
    "    pipeline = Pipeline(steps = [['scaler', scaler ],\n",
    "                                 ['smote', SMOTE(random_state=2021)],\n",
    "                                 ['classifier', svc]\n",
    "                                ])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(shuffle=True, n_splits=3, random_state=2021)\n",
    "\n",
    "    scoring = {\"accuracy\": \"accuracy\",\n",
    "               \"recall\": 'recall',\n",
    "               \"precision\": \"precision\",\n",
    "               \"fbeta_2\": make_scorer(fbeta_score, beta=2),\n",
    "               \"roc_auc\": make_scorer(roc_auc_score),\n",
    "              }\n",
    "\n",
    "    scores = cross_validate(pipeline, x_train, y_train.values.ravel(), cv=stratified_kfold,\n",
    "                           scoring = scoring)\n",
    "\n",
    "    accuracy = [ val for val in scores['test_accuracy'] ]\n",
    "    recall = [ val for val in scores['test_recall'] ]\n",
    "    precision = [ val for val in scores['test_precision'] ]\n",
    "    fbeta_2 = [ val for val in scores['test_fbeta_2'] ]\n",
    "    auc = [ val for val in scores['test_roc_auc'] ]\n",
    "\n",
    "    accuracy.append( sum(accuracy) / len(accuracy) )\n",
    "    recall.append( sum(recall) / len(recall) )\n",
    "    precision.append( sum(precision) / len(precision) )\n",
    "    fbeta_2.append( sum(fbeta_2) / len(fbeta_2) )\n",
    "    auc.append( sum(auc) / len(auc) )\n",
    "\n",
    "    score_df = pd.DataFrame(data=[accuracy, recall, precision, fbeta_2, auc], columns=['Fold 1','Fold 2','Fold 3', 'Average'],\n",
    "                                index=['Accuracy', 'Recall', 'Precision', 'Fbeta2', 'AUC'])\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.878193</td>\n",
       "      <td>0.885926</td>\n",
       "      <td>0.881852</td>\n",
       "      <td>0.881990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.841014</td>\n",
       "      <td>0.850230</td>\n",
       "      <td>0.841014</td>\n",
       "      <td>0.844086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.593479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fbeta2</th>\n",
       "      <td>0.772978</td>\n",
       "      <td>0.785775</td>\n",
       "      <td>0.776265</td>\n",
       "      <td>0.778339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.863162</td>\n",
       "      <td>0.871496</td>\n",
       "      <td>0.865344</td>\n",
       "      <td>0.866668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fold 1    Fold 2    Fold 3   Average\n",
       "Accuracy   0.878193  0.885926  0.881852  0.881990\n",
       "Recall     0.841014  0.850230  0.841014  0.844086\n",
       "Precision  0.584000  0.602941  0.593496  0.593479\n",
       "Fbeta2     0.772978  0.785775  0.776265  0.778339\n",
       "AUC        0.863162  0.871496  0.865344  0.866668"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svc_clf = SVC(random_state = 2021)\n",
    "base_model = cv_evaluate_model(svc_clf)\n",
    "display(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 First Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([[\"scaler\", MinMaxScaler()],\n",
    "                     [\"smote\", SMOTE(random_state = 2021)],\n",
    "                     [\"model\", SVC(random_state = 2021)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid =  { 'model__C': [0.1, 1, 10, 100, 1000],  \n",
    "               'model__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "               'model__kernel': ['rbf','linear','sigmoid']  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model__C [0.1, 1, 10, 100, 1000]\n",
      "model__gamma [1, 0.1, 0.01, 0.001, 0.0001]\n",
      "model__kernel ['rbf', 'linear', 'sigmoid']\n",
      "-----------------\n",
      "Total combinations: 75\n",
      "Total combinations across 5-folds: 375\n"
     ]
    }
   ],
   "source": [
    "total_combi = 1\n",
    "for param, value in param_grid.items():\n",
    "    print(param, value)\n",
    "    total_combi *= len(value)\n",
    "\n",
    "print('-----------------')\n",
    "print('Total combinations:', total_combi)\n",
    "print('Total combinations across 5-folds:', total_combi*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
      "Best Parameters:  {'model__C': 1000, 'model__gamma': 0.1, 'model__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svc_gridsearch1 = GridSearchCV(pipeline, param_grid, scoring = 'recall', cv = 5, n_jobs = -1, verbose = 1)\n",
    "svc_gridsearch1.fit(x_train, np.ravel(y_train))\n",
    "best_params = svc_gridsearch1.best_params_\n",
    "print(\"Best Parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Second Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best params of First Grid Search\n",
    "{'model__C': 1000, 'model__gamma': 0.1, 'model__kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid =  { 'model__C': [100, 1000, 10000],  \n",
    "               'model__gamma': [1, 0.1, 0.01], \n",
    "               'model__kernel': ['rbf']  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model__C [100, 1000, 10000]\n",
      "model__gamma [1, 0.1, 0.01]\n",
      "model__kernel ['rbf']\n",
      "-----------------\n",
      "Total combinations: 9\n",
      "Total combinations across 5-folds: 45\n"
     ]
    }
   ],
   "source": [
    "total_combi = 1\n",
    "for param, value in param_grid.items():\n",
    "    print(param, value)\n",
    "    total_combi *= len(value)\n",
    "\n",
    "print('-----------------')\n",
    "print('Total combinations:', total_combi)\n",
    "print('Total combinations across 5-folds:', total_combi*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters:  {'model__C': 1000, 'model__gamma': 0.1, 'model__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svm_gridsearch2 = GridSearchCV(pipeline, param_grid, scoring = 'recall', cv = 5, n_jobs = -1, verbose = 1)\n",
    "svm_gridsearch2.fit(x_train, np.ravel(y_train))\n",
    "best_params = svm_gridsearch2.best_params_\n",
    "print(\"Best Parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best params from First Grid Search:\n",
    "{'model__C': 1000, 'model__gamma': 0.1, 'model__kernel': 'rbf'}\n",
    "#### Best params from Second Grid Search:\n",
    "{'model__C': 1000, 'model__gamma': 0.1, 'model__kernel': 'rbf'}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
