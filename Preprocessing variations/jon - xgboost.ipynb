{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51dca08",
   "metadata": {},
   "source": [
    "# 1. Setting up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9681e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, fbeta_score, roc_auc_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b973afe6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "y_train = df_train[[\"attrition_flag\"]]\n",
    "x_train = df_train.drop(\"attrition_flag\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b62bd7",
   "metadata": {},
   "source": [
    "# 2. Running base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da01084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_evaluate_model(xgb):\n",
    "    scale_features = x_train.columns[1:]\n",
    "    oversampler = SMOTE(random_state=2021)\n",
    "\n",
    "    scaler = ColumnTransformer(transformers=[ ('scaler', MinMaxScaler(), scale_features) ])\n",
    "\n",
    "    pipeline = Pipeline(steps = [['scaler', scaler],\n",
    "                                 ['smote', oversampler],\n",
    "                                 ['classifier', xgb]\n",
    "                                ])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(shuffle=True, n_splits=5, random_state=2021)\n",
    "\n",
    "    scoring = {\"recall\": 'recall',\n",
    "               \"fbeta_2\": make_scorer(fbeta_score, beta=2),\n",
    "               \"roc_auc\": make_scorer(roc_auc_score),\n",
    "              }\n",
    "\n",
    "    scores = cross_validate(xgb, x_train, y_train.values.ravel(), cv=stratified_kfold, scoring=scoring)\n",
    "    recall = [ val for val in scores['test_recall'] ]\n",
    "    fbeta_2 = [ val for val in scores['test_fbeta_2'] ]\n",
    "    auc = [ val for val in scores['test_roc_auc'] ]\n",
    "    recall.append( sum(recall) / len(recall) )\n",
    "    fbeta_2.append( sum(fbeta_2) / len(fbeta_2) )\n",
    "    auc.append( sum(auc) / len(auc) )\n",
    "    score_df = pd.DataFrame(data=[recall, fbeta_2, auc], columns=['Fold 1','Fold 2','Fold 3', 'Fold 4', 'Fold 5', 'Average'],\n",
    "                            index=['Recall','Fbeta2','AUC'])\n",
    "    display(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b166ec65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.823755</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.865900</td>\n",
       "      <td>0.816393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fbeta2</th>\n",
       "      <td>0.840500</td>\n",
       "      <td>0.846931</td>\n",
       "      <td>0.784469</td>\n",
       "      <td>0.809748</td>\n",
       "      <td>0.869900</td>\n",
       "      <td>0.830310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.904524</td>\n",
       "      <td>0.908569</td>\n",
       "      <td>0.871946</td>\n",
       "      <td>0.886595</td>\n",
       "      <td>0.922281</td>\n",
       "      <td>0.898783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Fold 1    Fold 2    Fold 3    Fold 4    Fold 5   Average\n",
       "Recall  0.823755  0.838462  0.761538  0.792308  0.865900  0.816393\n",
       "Fbeta2  0.840500  0.846931  0.784469  0.809748  0.869900  0.830310\n",
       "AUC     0.904524  0.908569  0.871946  0.886595  0.922281  0.898783"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb = XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False, random_state=2021)\n",
    "cv_evaluate_model(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f528a",
   "metadata": {},
   "source": [
    "# 3. Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ba548",
   "metadata": {},
   "source": [
    "## 3.1 First Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12f4b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier__learning_rate [0.2, 0.3, 0.4, 0.5]\n",
      "classifier__max_depth [5, 10, 15, 20]\n",
      "classifier__gamma [0.2, 0.5, 0.7, 1.0]\n",
      "classifier__subsample [0.5, 0.6, 0.8, 0.9]\n",
      "-----------------\n",
      "Total combinations: 256\n"
     ]
    }
   ],
   "source": [
    "# https://blog.dataiku.com/narrowing-the-search-which-hyperparameters-really-matter\n",
    "# Creating parameter grid to search\n",
    "learning_rates = [0.2, 0.3, 0.4, 0.5]\n",
    "max_depths = [5, 10, 15, 20]\n",
    "gammas = [0.2, 0.5, 0.7, 1.0]\n",
    "subsamples = [0.5, 0.6, 0.8, 0.9]\n",
    "\n",
    "params_grid = {\n",
    "                'classifier__learning_rate': learning_rates,\n",
    "                'classifier__max_depth': max_depths,\n",
    "                'classifier__gamma': gammas,\n",
    "                'classifier__subsample': subsamples\n",
    "              }\n",
    "\n",
    "total_combi = 1\n",
    "for param, value in params_grid.items():\n",
    "    print(param, value)\n",
    "    total_combi *= len(value)\n",
    "\n",
    "print('-----------------')\n",
    "print('Total combinations:', total_combi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c95e9084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__gamma': 1.0, 'classifier__learning_rate': 0.3, 'classifier__max_depth': 5, 'classifier__subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "scale_features = x_train.columns[1:]\n",
    "oversampler = SMOTE(random_state=2021)\n",
    "scaler = ColumnTransformer(transformers=[ ('scaler', MinMaxScaler(), scale_features) ])\n",
    "xgb = XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False, random_state=2021)\n",
    "\n",
    "pipeline = Pipeline(steps = [['scaler', scaler],\n",
    "                             ['smote', oversampler],\n",
    "                             ['classifier', xgb]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(shuffle=True, n_splits=5, random_state=2021)\n",
    "\n",
    "xgb_gridsearch = GridSearchCV(\n",
    "                                estimator = pipeline,\n",
    "                                param_grid = params_grid,\n",
    "                                scoring = 'recall',\n",
    "                                cv = stratified_kfold,\n",
    "                                refit = True,\n",
    "                                n_jobs = -1\n",
    "                             )\n",
    "\n",
    "xgb_gridsearch.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print(xgb_gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef0958",
   "metadata": {},
   "source": [
    "## 3.2 Second Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5d812a",
   "metadata": {},
   "source": [
    "#### Best Params of First GridSearch\n",
    "{'classifier__gamma': 1.0, 'classifier__learning_rate': 0.3, \n",
    "'classifier__max_depth': 5, 'classifier__subsample': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "142a1001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__gamma': 1, 'classifier__learning_rate': 0.25, 'classifier__max_depth': 3, 'classifier__subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.25, 0.28, 0.3, 0.32, 0.35]\n",
    "max_depths = [3, 4, 5]\n",
    "gammas = [1]\n",
    "subsamples = [0.85, 0.9, 0.95]\n",
    "\n",
    "\n",
    "params_grid = {\n",
    "                'classifier__learning_rate': learning_rates,\n",
    "                'classifier__max_depth': max_depths,\n",
    "                'classifier__gamma': gammas,\n",
    "                'classifier__subsample': subsamples\n",
    "              }\n",
    "\n",
    "scale_features = x_train.columns[1:]\n",
    "oversampler = SMOTE(random_state=2021)\n",
    "scaler = ColumnTransformer(transformers=[ ('scaler', MinMaxScaler(), scale_features) ])\n",
    "xgb = XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False, random_state=2021)\n",
    "\n",
    "pipeline = Pipeline(steps = [['scaler', scaler],\n",
    "                             ['smote', oversampler],\n",
    "                             ['classifier', xgb]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(shuffle=True, n_splits=5, random_state=2021)\n",
    "\n",
    "xgb_gridsearch = GridSearchCV(\n",
    "                                estimator = pipeline,\n",
    "                                param_grid = params_grid,\n",
    "                                scoring = 'recall',\n",
    "                                cv = stratified_kfold,\n",
    "                                refit = True,\n",
    "                                n_jobs = -1\n",
    "                             )\n",
    "\n",
    "xgb_gridsearch.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print(xgb_gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f32863",
   "metadata": {},
   "source": [
    "## 3.3 Third Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd605d",
   "metadata": {},
   "source": [
    "#### Best params from Second Grid Search:\n",
    "{'classifier__gamma': 1, 'classifier__learning_rate': 0.25, 'classifier__max_depth': 3, 'classifier__subsample': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af7ccad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__gamma': 1, 'classifier__learning_rate': 0.25, 'classifier__max_depth': 3, 'classifier__subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.22, 0.23, 0.24, 0.25, 0.26]\n",
    "max_depths = [3]\n",
    "gamma = [1]\n",
    "subsamples = [0.87, 0.9, 0.92]\n",
    "\n",
    "params_grid = {\n",
    "                'classifier__learning_rate': learning_rates,\n",
    "                'classifier__max_depth': max_depths,\n",
    "                'classifier__gamma': gammas,\n",
    "                'classifier__subsample': subsamples\n",
    "              }\n",
    "\n",
    "scale_features = x_train.columns[1:]\n",
    "oversampler = SMOTE(random_state=2021)\n",
    "scaler = ColumnTransformer(transformers=[ ('scaler', MinMaxScaler(), scale_features) ])\n",
    "xgb = XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False, random_state=2021)\n",
    "\n",
    "pipeline = Pipeline(steps = [['scaler', scaler],\n",
    "                             ['smote', oversampler],\n",
    "                             ['classifier', xgb]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(shuffle=True, n_splits=5, random_state=2021)\n",
    "\n",
    "xgb_gridsearch = GridSearchCV(\n",
    "                                estimator = pipeline,\n",
    "                                param_grid = params_grid,\n",
    "                                scoring = 'recall',\n",
    "                                cv = stratified_kfold,\n",
    "                                refit = True,\n",
    "                                n_jobs = -1\n",
    "                             )\n",
    "\n",
    "xgb_gridsearch.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print(xgb_gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aecf4b",
   "metadata": {},
   "source": [
    "# 4. Evaluation on test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6fdc6",
   "metadata": {},
   "source": [
    "#### Best params from Second Grid Search:\n",
    "{'classifier__gamma': 1, 'classifier__learning_rate': 0.25, 'classifier__max_depth': 3, 'classifier__subsample': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae40c1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------TEST SCORES-----------------------  \n",
      "Recall: 0.8738461538461538  \n",
      "Fbeta2: 0.8647990255785628  \n",
      "AUC Score: 0.9198742820965042  \n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data/test.csv\")\n",
    "y_test = df_test[[\"attrition_flag\"]]\n",
    "x_test = df_test.drop(\"attrition_flag\", axis=1)\n",
    "\n",
    "scale_features = x_train.columns[1:]\n",
    "oversampler = SMOTE(random_state=2021)\n",
    "scaler = ColumnTransformer(transformers=[ ('scaler', MinMaxScaler(), scale_features) ])\n",
    "xgb = XGBClassifier(learning_rate=0.25,\n",
    "                    max_depth=3,\n",
    "                    gamma=1,\n",
    "                    subsample=0.9,\n",
    "                    eval_metric=\"logloss\", \n",
    "                    use_label_encoder=False, \n",
    "                    random_state=2021)\n",
    "\n",
    "pipeline = Pipeline(steps = [['scaler', scaler],\n",
    "                             ['smote', oversampler],\n",
    "                             ['classifier', xgb]])\n",
    "\n",
    "pipeline.fit(x_train, y_train.values.ravel() )\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "print(\"-------------------------TEST SCORES-----------------------  \")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}  \")\n",
    "print(f\"Fbeta2: {fbeta_score(y_test, y_pred, beta=2)}  \")\n",
    "print(f\"AUC Score: {roc_auc_score(y_test, y_pred)}  \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
