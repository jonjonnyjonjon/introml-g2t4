{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS421: Introduction to Machine Learning\n",
    "## Project: Predicting Credit Card Customer Churn\n",
    "### Model: Support Vector Machine\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing packages & libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, recall_score, precision_score, f1_score, fbeta_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading file & tidying up columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[[\"attrition_flag\"]]\n",
    "x_train = df_train.drop(\"attrition_flag\", axis=1)\n",
    "\n",
    "y_test = df_test[[\"attrition_flag\"]]\n",
    "x_test = df_test.drop(\"attrition_flag\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(train_x, y_train, test_x, y_test, variation):\n",
    "\n",
    "    x_train = train_x.copy()\n",
    "    x_test = test_x.copy()\n",
    "    \n",
    "    if variation == \"correlation\":\n",
    "        x_train.drop( ['avg_open_to_buy', 'customer_age', 'total_trans_count', 'months_on_book'], axis=1, inplace=True)\n",
    "        x_test.drop( ['avg_open_to_buy', 'customer_age', 'total_trans_count', 'months_on_book'], axis=1, inplace=True)\n",
    "        \n",
    "    if variation == \"keep_yellow_only\":\n",
    "        x_train.drop( ['total_trans_count', 'months_on_book', 'card_category', 'education_level', 'income_category', 'married', 'single','divorced', 'avg_open_to_buy', 'customer_age'], axis=1, inplace=True)\n",
    "        x_test.drop( ['total_trans_count', 'months_on_book', 'card_category', 'education_level', 'income_category', 'married', 'single', 'divorced', 'avg_open_to_buy', 'customer_age'], axis=1, inplace=True)\n",
    "    \n",
    "    if variation == \"keep_yellow_blue\":\n",
    "        x_train.drop( ['total_trans_count', 'months_on_book', 'income_category', 'married', 'single', 'divorced', 'avg_open_to_buy', 'customer_age'], axis=1, inplace=True)\n",
    "        x_test.drop( ['total_trans_count', 'months_on_book', 'income_category', 'married', 'single', 'divorced', 'avg_open_to_buy', 'customer_age'], axis=1, inplace=True)\n",
    "    \n",
    "    # need to explore more on various SVM & hyperparameter tuning (WIP)\n",
    "    svm = SVC(random_state=2021)\n",
    "    \n",
    "    oversampler = SMOTE(random_state=2021)\n",
    "    x_train, y_train = oversampler.fit_resample(x_train, y_train)\n",
    "\n",
    "    svm.fit(x_train, np.ravel(y_train))\n",
    "    y_pred = svm.predict(x_test)       \n",
    "    \n",
    "    print(f\"-------------------------TEST SCORES for {variation}-----------------------\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"F2-Score: {fbeta_score(y_test, y_pred, beta=2)}\")\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"AUC Score: {roc_auc_score(y_test, y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------TEST SCORES for correlation-----------------------\n",
      "Recall: 0.72\n",
      "Precision: 0.5064935064935064\n",
      "F2-Score: 0.6640181611804766\n",
      "Accuracy score: 0.8425468904244817\n",
      "AUC Score: 0.7929805996472663\n",
      "\n",
      "-------------------------TEST SCORES for keep_yellow_only-----------------------\n",
      "Recall: 0.7815384615384615\n",
      "Precision: 0.5759637188208617\n",
      "F2-Score: 0.7294658242389432\n",
      "Accuracy score: 0.8726554787759131\n",
      "AUC Score: 0.8358015646904536\n",
      "\n",
      "-------------------------TEST SCORES for keep_yellow_blue-----------------------\n",
      "Recall: 0.72\n",
      "Precision: 0.5064935064935064\n",
      "F2-Score: 0.6640181611804766\n",
      "Accuracy score: 0.8425468904244817\n",
      "AUC Score: 0.7929805996472663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variations = ['correlation', 'keep_yellow_only', 'keep_yellow_blue']\n",
    "\n",
    "for variation in variations:\n",
    "    run_models(x_train, y_train, x_test, y_test, variation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Testing accuracy %s' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_test, y_pred, labels=svm.classes_)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = svm.classes_)\n",
    "# disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "# print(\"AUC:\", auc(false_positive_rate, true_positive_rate))\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred.round()))\n",
    "# print(\"Precision:\", precision_score(y_test, y_pred.round()))\n",
    "# print(\"Recall:\", recall_score(y_test, y_pred.round(), average='macro'))\n",
    "# print(\"f1_score:\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on Train Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Explained Variance Ratio w.r.t Number of Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_test = PCA(n)\n",
    "# pca_test.fit(x_train)\n",
    "# sns.set(style='whitegrid')\n",
    "# plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')\n",
    "# evr = pca_test.explained_variance_ratio_\n",
    "# cvr = np.cumsum(pca_test.explained_variance_ratio_)\n",
    "# pca_df = pd.DataFrame()\n",
    "# pca_df['Cumulative Variance Ratio'] = cvr\n",
    "# pca_df['Explained Variance Ratio'] = evr\n",
    "# display(pca_df)\n",
    "\n",
    "# # decision boundary of at least 90% of cumulative explained variance\n",
    "# plt.axhline(color='r', y=0.9)\n",
    "\n",
    "# # ideal number of components -> 4 components \n",
    "# plt.axvline(color='r', linewidth=4, linestyle='--', x=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
