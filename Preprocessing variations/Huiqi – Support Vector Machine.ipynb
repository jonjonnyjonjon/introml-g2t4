{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS421: Introduction to Machine Learning\n",
    "## Project: Predicting Credit Card Customer Churn\n",
    "### Model: Support Vector Machine\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing packages & libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, recall_score, precision_score, f1_score, fbeta_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading file & tidying up columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[[\"attrition_flag\"]]\n",
    "x_train = df_train.drop(\"attrition_flag\", axis=1)\n",
    "\n",
    "y_test = df_test[[\"attrition_flag\"]]\n",
    "x_test = df_test.drop(\"attrition_flag\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pipeline for GridSearch ( Min-max scale, SMOTE, SVM classifier )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([( \"scaler\" , MinMaxScaler()),\n",
    "                     (\"smote\", SMOTE(random_state = 2021)), \n",
    "                     (\"model\", SVC(random_state=2021))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating parameter grid to be used for GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid =  { 'model__C': [0.1, 1, 10, 100, 1000],  \n",
    "               'model__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "               'model__kernel': ['rbf','linear','sigmoid']  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model__C [0.1, 1, 10, 100, 1000]\n",
      "model__gamma [1, 0.1, 0.01, 0.001, 0.0001]\n",
      "model__kernel ['rbf', 'linear', 'sigmoid']\n",
      "-----------------\n",
      "Total combinations: 75\n"
     ]
    }
   ],
   "source": [
    "total_combi = 1\n",
    "for param, value in param_grid.items():\n",
    "    print(param, value)\n",
    "    total_combi *= len(value)\n",
    "\n",
    "print('-----------------')\n",
    "print('Total combinations:', total_combi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running GridSearchCV to get best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_gridsearch = GridSearchCV(pipeline, param_grid, scoring = 'recall', cv = 5, n_jobs = -1, verbose = 1)\n",
    "svm_gridsearch.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Best Parameters from GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = svm_gridsearch.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = svm_gridsearch.best_estimator_\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "print(f\"-------------------------TEST SCORES-----------------------\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F2-Score: {fbeta_score(y_test, y_pred, beta=2)}\")\n",
    "print(f\"AUC Score: {roc_auc_score(y_test, y_pred)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc (to be removed later)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = SVC(random_state=2021)\n",
    "\n",
    "# # Applying SMOTE for oversampling\n",
    "# oversampler = SMOTE(random_state=2021)\n",
    "# x_train, y_train = oversampler.fit_resample(x_train, y_train)\n",
    "\n",
    "# svm.fit(x_train, np.ravel(y_train))\n",
    "# y_pred = svm.predict(x_test) \n",
    "\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print(f\"------------------------ TEST SCORES -----------------------\")\n",
    "# print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "# print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "# print(f\"F2-Score: {fbeta_score(y_test, y_pred, beta=2)}\")\n",
    "# print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")\n",
    "# print(f\"AUC Score: {roc_auc_score(y_test, y_pred)}\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4):\n",
    "#     # Separate data into test and training sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)# Train a SVC model using different kernal\n",
    "#     svclassifier = getClassifier(i) \n",
    "#     svclassifier.fit(X_train, y_train)# Make prediction\n",
    "#     y_pred = svclassifier.predict(X_test)# Evaluate our model\n",
    "#     print(\"Evaluation:\", kernals[i], \"kernel\")\n",
    "#     print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_models(train_x, y_train, test_x, y_test, variation):\n",
    "\n",
    "#     x_train = train_x.copy()\n",
    "#     x_test = test_x.copy()\n",
    "    \n",
    "#     if variation == \"correlation\":\n",
    "#         x_train.drop( ['avg_open_to_buy', 'customer_age', 'total_trans_count', 'months_on_book'], axis=1, inplace=True)\n",
    "#         x_test.drop( ['avg_open_to_buy', 'customer_age', 'total_trans_count', 'months_on_book'], axis=1, inplace=True)\n",
    "        \n",
    "#     if variation == \"keep_yellow_only\":\n",
    "#         x_train.drop( ['total_trans_count', 'months_on_book', 'card_category', 'education_level', 'income_category', 'married', 'single','divorced', 'avg_open_to_buy', 'customer_age'], axis=1, inplace=True)\n",
    "#         x_test.drop( ['total_trans_count', 'months_on_book', 'card_category', 'education_level', 'income_category', 'married', 'single', 'divorced', 'avg_open_to_buy', 'customer_age'], axis=1, inplace=True)\n",
    "    \n",
    "#     if variation == \"keep_yellow_blue\":\n",
    "#         x_train.drop( ['total_trans_count', 'months_on_book', 'income_category', 'married', 'single', 'divorced', 'avg_open_to_buy', 'customer_age'], axis=1, inplace=True)\n",
    "#         x_test.drop( ['total_trans_count', 'months_on_book', 'income_category', 'married', 'single', 'divorced', 'avg_open_to_buy', 'customer_age'], axis=1, inplace=True)\n",
    "    \n",
    "#     # need to explore more on various SVM & hyperparameter tuning (WIP)\n",
    "#     svm = SVC(random_state=2021)\n",
    "    \n",
    "#     oversampler = SMOTE(random_state=2021)\n",
    "#     x_train, y_train = oversampler.fit_resample(x_train, y_train)\n",
    "\n",
    "#     svm.fit(x_train, np.ravel(y_train))\n",
    "#     y_pred = svm.predict(x_test)       \n",
    "    \n",
    "#     print(f\"-------------------------TEST SCORES for {variation}-----------------------\")\n",
    "#     print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "#     print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "#     print(f\"F2-Score: {fbeta_score(y_test, y_pred, beta=2)}\")\n",
    "#     print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")\n",
    "#     print(f\"AUC Score: {roc_auc_score(y_test, y_pred)}\")\n",
    "#     print()\n",
    "\n",
    "# variations = ['correlation', 'keep_yellow_only', 'keep_yellow_blue']\n",
    "\n",
    "# for variation in variations:\n",
    "#     run_models(x_train, y_train, x_test, y_test, variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Testing accuracy %s' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_test, y_pred, labels=svm.classes_)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = svm.classes_)\n",
    "# disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "# print(\"AUC:\", auc(false_positive_rate, true_positive_rate))\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred.round()))\n",
    "# print(\"Precision:\", precision_score(y_test, y_pred.round()))\n",
    "# print(\"Recall:\", recall_score(y_test, y_pred.round(), average='macro'))\n",
    "# print(\"f1_score:\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on Train Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Explained Variance Ratio w.r.t Number of Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_test = PCA(n)\n",
    "# pca_test.fit(x_train)\n",
    "# sns.set(style='whitegrid')\n",
    "# plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')\n",
    "# evr = pca_test.explained_variance_ratio_\n",
    "# cvr = np.cumsum(pca_test.explained_variance_ratio_)\n",
    "# pca_df = pd.DataFrame()\n",
    "# pca_df['Cumulative Variance Ratio'] = cvr\n",
    "# pca_df['Explained Variance Ratio'] = evr\n",
    "# display(pca_df)\n",
    "\n",
    "# # decision boundary of at least 90% of cumulative explained variance\n",
    "# plt.axhline(color='r', y=0.9)\n",
    "\n",
    "# # ideal number of components -> 4 components \n",
    "# plt.axvline(color='r', linewidth=4, linestyle='--', x=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
