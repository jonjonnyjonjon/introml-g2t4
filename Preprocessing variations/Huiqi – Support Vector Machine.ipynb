{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS421: Introduction to Machine Learning\n",
    "## Project: Predicting Credit Card Customer Churn\n",
    "### Model: Support Vector Machine\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing packages & libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyforest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "val_df = pd.read_csv('../Data/validation.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "dataset_df = pd.read_csv('../Data/BankChurners.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading file & tidying up columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/BankChurners.csv')\n",
    "df = df.iloc[:,1:-2] # dropping first & last 2 columns \n",
    "\n",
    "tidied_cols = []\n",
    "for col_name in df.columns:\n",
    "    col_name = col_name.lower()\n",
    "    if '_ct' in col_name:\n",
    "        col_name = col_name.replace('_ct', '_count')\n",
    "    if '_chng' in col_name:\n",
    "        col_name = col_name.replace('_chng', '_change')\n",
    "    tidied_cols.append( col_name )\n",
    "    \n",
    "df.columns = tidied_cols.copy()\n",
    "\n",
    "df = df.drop(columns=[\"customer_age\", \"avg_open_to_buy\", \"total_trans_count\"]) # dropping correlated features\n",
    "\n",
    "# defining numerical & categorical columns\n",
    "numerical = list(df.describe().columns)\n",
    "categorical = [i for i in df.columns if i not in numerical and i != \"attrition_flag\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"attrition_flag\"]]\n",
    "x = df.drop(\"attrition_flag\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute unknown values in train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_unknown(df_x):\n",
    "    \"\"\"\n",
    "        Imputes unknown values to their mode\n",
    "    \"\"\"\n",
    "    x = df_x.copy()\n",
    "\n",
    "    marital_status_mode = x[\"marital_status\"].mode()[0]\n",
    "    x[\"marital_status\"] = x[\"marital_status\"].replace(\"Unknown\", marital_status_mode)\n",
    "    education_level_mode = x[\"education_level\"].mode()[0]\n",
    "    x[\"education_level\"] = x[\"education_level\"].replace(\"Unknown\", education_level_mode)\n",
    "    income_category_mode = x[\"income_category\"].mode()[0]\n",
    "    x[\"income_category\"] = x[\"income_category\"].replace(\"Unknown\", income_category_mode)\n",
    "    \n",
    "    return x\n",
    "\n",
    "x_train = impute_unknown(x_train)\n",
    "x_test = impute_unknown(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import OneHotEncoder'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import OneHotEncoder'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import OneHotEncoder'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import OneHotEncoder'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import LabelEncoder\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import OneHotEncoder'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def data_preprocessing(df_x, df_y):\n",
    "    x = df_x.copy()\n",
    "    y = df_y.copy()\n",
    "    \n",
    "    # Encoding features with binary categories\n",
    "    label_enc = LabelEncoder()\n",
    "    y[\"attrition_flag\"] = label_enc.fit_transform(y[\"attrition_flag\"])\n",
    "    x[\"gender\"] = label_enc.fit_transform(x[\"gender\"])\n",
    "    \n",
    "    # Encoding features with multiple categories\n",
    "    onehot_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    values = onehot_enc.fit_transform(x[[\"marital_status\"]])\n",
    "    labels = np.array([\"divorced\", \"married\", \"single\"]).ravel()\n",
    "    marital_status_df = pd.DataFrame(values, columns=labels)\n",
    "\n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "    marital_status_df.reset_index(drop=True, inplace=True)\n",
    "    x = pd.concat([x, marital_status_df], axis=1)\n",
    "    x.drop(\"marital_status\", axis=1, inplace=True)\n",
    "    \n",
    "    # Encoding Ordinal Features\n",
    "    edu_level_mapper = {\"Doctorate\": 1, \"Post-Graduate\": 2, \"Graduate\": 3, \"College\": 4, \"High School\": 5, \"Uneducated\": 6}\n",
    "    x[\"education_level\"] = x[\"education_level\"].replace(edu_level_mapper)\n",
    "\n",
    "    income_cat_mapper = {\"$120K +\": 1, \"$80K - $120K\":2, \"$60K - $80K\":3, \"$40K - $60K\": 4, \"Less than $40K\": 5}\n",
    "    x[\"income_category\"] = x[\"income_category\"].replace(income_cat_mapper)\n",
    "\n",
    "    card_cat_mapper = {\"Platinum\":1, \"Gold\":2, \"Silver\":3, \"Blue\": 4}\n",
    "    x[\"card_category\"] = x[\"card_category\"].replace(card_cat_mapper)\n",
    "    \n",
    "    # Feature Transformation â€” Scaling\n",
    "    skewed = [\"credit_limit\", \"total_amt_change_q4_q1\", \"total_trans_amt\", \"total_count_change_q4_q1\"]\n",
    "\n",
    "    for skewed_col in skewed:\n",
    "#         x[skewed_col] = np.where(x[skewed_col] > 0 , np.log(x[skewed_col]), 0) # not using, leaving here for now\n",
    "        x[skewed_col] = np.log(x[skewed_col].mask(x[skewed_col] <=0)).fillna(0)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    x[numerical] = scaler.fit_transform(x[numerical]) \n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = data_preprocessing(x_train, y_train)\n",
    "x_test, y_test = data_preprocessing(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Running SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/31/58wwhf4j5sd5_02_6gcrsqsc0000gn/T/ipykernel_12112/374595379.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'svc' is not defined"
     ]
    }
   ],
   "source": [
    "# need to explore more on various SVM & hyperparameter tuning (WIP)\n",
    "svm = SVC(random_state=0)\n",
    "svm.fit(x_train, np.ravel(y_train))\n",
    "y_pred = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=svm.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = svm.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "print(\"AUC:\", auc(false_positive_rate, true_positive_rate))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred.round()))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred.round()))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred.round(), average='macro'))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on Train Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Explained Variance Ratio w.r.t Number of Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test = PCA(n_components = 18)\n",
    "pca_test.fit(x_train)\n",
    "sns.set(style='whitegrid')\n",
    "plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "evr = pca_test.explained_variance_ratio_\n",
    "cvr = np.cumsum(pca_test.explained_variance_ratio_)\n",
    "pca_df = pd.DataFrame()\n",
    "pca_df['Cumulative Variance Ratio'] = cvr\n",
    "pca_df['Explained Variance Ratio'] = evr\n",
    "display(pca_df)\n",
    "\n",
    "# decision boundary of at least 90% of cumulative explained variance\n",
    "plt.axhline(color='r', y=0.9)\n",
    "\n",
    "# ideal number of components -> 4 components \n",
    "plt.axvline(color='r', linewidth=4, linestyle='--', x=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
