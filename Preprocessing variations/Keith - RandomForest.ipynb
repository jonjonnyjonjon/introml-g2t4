{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b687c1",
   "metadata": {},
   "source": [
    "# CS421: Introduction to Machine Learning\n",
    "## Project: Predicting Credit Card Customer Churn\n",
    "### Model: Random Forest\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91de7de",
   "metadata": {},
   "source": [
    "# 1. Importing packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c0ac262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, fbeta_score, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b6d45",
   "metadata": {},
   "source": [
    "# 2. Reading file and tidying up columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bd937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/BankChurners.csv\")\n",
    "df.drop(columns=[\"CLIENTNUM\", \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\", \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"], axis=1, inplace=True)\n",
    "df = df.drop(columns=[\"Customer_Age\", \"Avg_Open_To_Buy\", \"Total_Trans_Ct\"])\n",
    "df.columns = ['attrition_flag', 'gender', 'dependent_count', 'education_level', \n",
    "              'marital_status', 'income_category', 'card_category', 'months_on_book', \n",
    "              'total_relationship_count', 'months_inactive_12_month', 'contacts_count_12_month', \n",
    "              'credit_limit', 'total_revolving_bal', 'total_amt_change_q4_q1', \n",
    "              'total_trans_amt','total_count_change_q4_q1', 'avg_utilization_ratio']\n",
    "\n",
    "numerical = ['dependent_count', 'months_on_book', \n",
    "             'total_relationship_count', 'months_inactive_12_month',\n",
    "             'contacts_count_12_month', 'credit_limit', 'total_revolving_bal',\n",
    "             'total_amt_change_q4_q1', 'total_trans_amt',\n",
    "             'total_count_change_q4_q1', 'avg_utilization_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b341c6",
   "metadata": {},
   "source": [
    "# 3. Create train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe82b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   gender                    10127 non-null  object \n",
      " 1   dependent_count           10127 non-null  int64  \n",
      " 2   education_level           10127 non-null  object \n",
      " 3   marital_status            10127 non-null  object \n",
      " 4   income_category           10127 non-null  object \n",
      " 5   card_category             10127 non-null  object \n",
      " 6   months_on_book            10127 non-null  int64  \n",
      " 7   total_relationship_count  10127 non-null  int64  \n",
      " 8   months_inactive_12_month  10127 non-null  int64  \n",
      " 9   contacts_count_12_month   10127 non-null  int64  \n",
      " 10  credit_limit              10127 non-null  float64\n",
      " 11  total_revolving_bal       10127 non-null  int64  \n",
      " 12  total_amt_change_q4_q1    10127 non-null  float64\n",
      " 13  total_trans_amt           10127 non-null  int64  \n",
      " 14  total_count_change_q4_q1  10127 non-null  float64\n",
      " 15  avg_utilization_ratio     10127 non-null  float64\n",
      "dtypes: float64(4), int64(7), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "y = df[[\"attrition_flag\"]]\n",
    "x = df.drop(\"attrition_flag\", axis=1)\n",
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d45285",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f4339",
   "metadata": {},
   "source": [
    "# 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cccddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_unknown(df_x):\n",
    "    \"\"\"\n",
    "        Imputes unknown values to their mode\n",
    "    \"\"\"\n",
    "    x = df_x.copy()\n",
    "\n",
    "    marital_status_mode = x[\"marital_status\"].mode()[0]\n",
    "    x[\"marital_status\"] = x[\"marital_status\"].replace(\"Unknown\", marital_status_mode)\n",
    "    education_level_mode = x[\"education_level\"].mode()[0]\n",
    "    x[\"education_level\"] = x[\"education_level\"].replace(\"Unknown\", education_level_mode)\n",
    "    income_category_mode = x[\"income_category\"].mode()[0]\n",
    "    x[\"income_category\"] = x[\"income_category\"].replace(\"Unknown\", income_category_mode)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "x_train = impute_unknown(x_train)\n",
    "x_test = impute_unknown(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3210510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df_x, df_y):\n",
    "    x = df_x.copy()\n",
    "    y = df_y.copy()\n",
    "    \n",
    "    # Encoding features with binary categories\n",
    "    label_enc = LabelEncoder()\n",
    "    y[\"attrition_flag\"] = label_enc.fit_transform(y[\"attrition_flag\"])\n",
    "    x[\"gender\"] = label_enc.fit_transform(x[\"gender\"])\n",
    "    \n",
    "    # Encoding features with multiple categories\n",
    "    onehot_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    values = onehot_enc.fit_transform(x[[\"marital_status\"]])\n",
    "    labels = np.array([\"divorced\", \"married\", \"single\"]).ravel()\n",
    "    marital_status_df = pd.DataFrame(values, columns=labels)\n",
    "\n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "    marital_status_df.reset_index(drop=True, inplace=True)\n",
    "    x = pd.concat([x, marital_status_df], axis=1)\n",
    "    x.drop(\"marital_status\", axis=1, inplace=True)\n",
    "    \n",
    "    # Encoding Ordinal Features\n",
    "    edu_level_mapper = {\"Doctorate\": 1, \"Post-Graduate\": 2, \"Graduate\": 3, \"College\": 4, \"High School\": 5, \"Uneducated\": 6}\n",
    "    x[\"education_level\"] = x[\"education_level\"].replace(edu_level_mapper)\n",
    "\n",
    "    income_cat_mapper = {\"$120K +\": 1, \"$80K - $120K\":2, \"$60K - $80K\":3, \"$40K - $60K\": 4, \"Less than $40K\": 5}\n",
    "    x[\"income_category\"] = x[\"income_category\"].replace(income_cat_mapper)\n",
    "\n",
    "    card_cat_mapper = {\"Platinum\":1, \"Gold\":2, \"Silver\":3, \"Blue\": 4}\n",
    "    x[\"card_category\"] = x[\"card_category\"].replace(card_cat_mapper)\n",
    "    \n",
    "    # Feature Transformation â€” Scaling\n",
    "    skewed = [\"credit_limit\", \"total_amt_change_q4_q1\", \"total_trans_amt\", \"total_count_change_q4_q1\"]\n",
    "\n",
    "    for skewed_col in skewed:\n",
    "#         x[skewed_col] = np.where(x[skewed_col] > 0 , np.log(x[skewed_col]), 0) # not using, leaving here for now\n",
    "        x[skewed_col] = np.log(x[skewed_col].mask(x[skewed_col] <=0)).fillna(0)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    x[numerical] = scaler.fit_transform(x[numerical]) \n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae39dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute preprocessing steps\n",
    "x_train, y_train = data_preprocessing(x_train, y_train)\n",
    "x_test, y_test = data_preprocessing(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f2fcd0",
   "metadata": {},
   "source": [
    "# 5. Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8f39df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_variation_model(x_train, y_train, x_test, y_test, variation):\n",
    "    if \"pca\" in variation:\n",
    "        pca = PCA(0.9, random_state=2021)\n",
    "        x_train = pca.fit_transform(x_train)\n",
    "        x_test = pca.fit_transform(x_test)\n",
    "        \n",
    "#     https://medium.com/analytics-vidhya/categorical-feature-selection-using-chi-squared-test-e4c0d0af6b7e\n",
    "#     https://towardsdatascience.com/using-the-chi-squared-test-for-feature-selection-with-implementation-b15a4dad93f1\n",
    "    if \"chi_square\" in variation:\n",
    "        selector = SelectKBest(score_func=chi2, k=8)\n",
    "        fit = selector.fit(x_train, y_train)\n",
    "        kbest_cols = x_train.columns[ selector.get_support() ]\n",
    "        drop_cols = [ col for col in x_train.columns if col not in kbest_cols]\n",
    "        print(drop_cols)\n",
    "        \n",
    "    if \"smote\" in variation:\n",
    "        oversampler = SMOTE(random_state=2021)\n",
    "        x_train, y_train = oversampler.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # Instantiate RandomClassifier, fit and predict\n",
    "    rf_clf = RandomForestClassifier(random_state=2021)\n",
    "    \n",
    "    rf_clf.fit(x_train, y_train.values.ravel() )\n",
    "    y_pred = rf_clf.predict(x_test)\n",
    "    \n",
    "    print(f\"-------------------------TEST SCORES for {variation}-----------------------\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"F2-Score: {fbeta_score(y_test, y_pred, beta=2)}\")\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"AUC Score: {roc_auc_score(y_test, y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f7362a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------TEST SCORES for base-----------------------\n",
      "Recall: 0.9870664315108759\n",
      "Precision: 0.9491237987563595\n",
      "F2-Score: 0.9792371398576928\n",
      "Accuracy score: 0.9447186574531096\n",
      "AUC Score: 0.8550716772938995\n",
      "\n",
      "-------------------------TEST SCORES for smote-----------------------\n",
      "Recall: 0.9653145208700764\n",
      "Precision: 0.9546511627906977\n",
      "F2-Score: 0.9631628343500703\n",
      "Accuracy score: 0.9323790720631787\n",
      "AUC Score: 0.8626572604350382\n",
      "\n",
      "['dependent_count', 'education_level', 'income_category', 'card_category', 'months_on_book', 'credit_limit', 'total_amt_change_q4_q1', 'divorced', 'married', 'single']\n",
      "-------------------------TEST SCORES for chi_square-----------------------\n",
      "Recall: 0.9870664315108759\n",
      "Precision: 0.9491237987563595\n",
      "F2-Score: 0.9792371398576928\n",
      "Accuracy score: 0.9447186574531096\n",
      "AUC Score: 0.8550716772938995\n",
      "\n",
      "-------------------------TEST SCORES for pca-----------------------\n",
      "Recall: 0.974132863021752\n",
      "Precision: 0.8441161487519103\n",
      "F2-Score: 0.9450211018592449\n",
      "Accuracy score: 0.8272458045409674\n",
      "AUC Score: 0.5162972007416452\n",
      "\n",
      "['dependent_count', 'education_level', 'income_category', 'card_category', 'months_on_book', 'credit_limit', 'total_amt_change_q4_q1', 'divorced', 'married', 'single']\n",
      "-------------------------TEST SCORES for smote, chi_square-----------------------\n",
      "Recall: 0.9653145208700764\n",
      "Precision: 0.9546511627906977\n",
      "F2-Score: 0.9631628343500703\n",
      "Accuracy score: 0.9323790720631787\n",
      "AUC Score: 0.8626572604350382\n",
      "\n",
      "-------------------------TEST SCORES for smote, pca-----------------------\n",
      "Recall: 0.8271604938271605\n",
      "Precision: 0.866913123844732\n",
      "F2-Score: 0.8348166607333571\n",
      "Accuracy score: 0.7482724580454096\n",
      "AUC Score: 0.5812725546058879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variations = [\"base\",\n",
    "              \"smote\",\n",
    "              \"chi_square\",\n",
    "              \"pca\",\n",
    "              \"smote, chi_square\",\n",
    "              \"smote, pca\"]\n",
    "\n",
    "for variation in variations:\n",
    "    run_variation_model(x_train, y_train, x_test, y_test, variation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
