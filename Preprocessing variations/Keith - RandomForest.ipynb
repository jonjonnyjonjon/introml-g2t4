{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b687c1",
   "metadata": {},
   "source": [
    "# CS421: Introduction to Machine Learning\n",
    "## Project: Predicting Credit Card Customer Churn\n",
    "### Model: Random Forest\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91de7de",
   "metadata": {},
   "source": [
    "# 1. Importing packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b335f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, fbeta_score, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d734cd",
   "metadata": {},
   "source": [
    "# 2. Reading file and tidying up columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4817f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/BankChurners.csv\")\n",
    "df.drop(columns=[\"CLIENTNUM\", \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\", \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"], axis=1, inplace=True)\n",
    "\n",
    "# tidy up and standardise column naming\n",
    "tidied_cols = []\n",
    "for col_name in df.columns:\n",
    "    col_name = col_name.lower()\n",
    "    if '_ct' in col_name:\n",
    "        col_name = col_name.replace('_ct', '_count')\n",
    "    if '_chng' in col_name:\n",
    "        col_name = col_name.replace('_chng', '_change')\n",
    "    tidied_cols.append( col_name )\n",
    "\n",
    "df.columns = tidied_cols.copy()\n",
    "\n",
    "numerical = list(df.describe().columns)\n",
    "\n",
    "categorical = [i for i in df.columns if i not in numerical and i != \"attrition_flag\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fbe10e",
   "metadata": {},
   "source": [
    "# 3. Create train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e33378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   customer_age              10127 non-null  int64  \n",
      " 1   gender                    10127 non-null  object \n",
      " 2   dependent_count           10127 non-null  int64  \n",
      " 3   education_level           10127 non-null  object \n",
      " 4   marital_status            10127 non-null  object \n",
      " 5   income_category           10127 non-null  object \n",
      " 6   card_category             10127 non-null  object \n",
      " 7   months_on_book            10127 non-null  int64  \n",
      " 8   total_relationship_count  10127 non-null  int64  \n",
      " 9   months_inactive_12_mon    10127 non-null  int64  \n",
      " 10  contacts_count_12_mon     10127 non-null  int64  \n",
      " 11  credit_limit              10127 non-null  float64\n",
      " 12  total_revolving_bal       10127 non-null  int64  \n",
      " 13  avg_open_to_buy           10127 non-null  float64\n",
      " 14  total_amt_change_q4_q1    10127 non-null  float64\n",
      " 15  total_trans_amt           10127 non-null  int64  \n",
      " 16  total_trans_count         10127 non-null  int64  \n",
      " 17  total_count_change_q4_q1  10127 non-null  float64\n",
      " 18  avg_utilization_ratio     10127 non-null  float64\n",
      "dtypes: float64(5), int64(9), object(5)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "y = df[[\"attrition_flag\"]]\n",
    "x = df.drop(\"attrition_flag\", axis=1)\n",
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f8290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c1e0e",
   "metadata": {},
   "source": [
    "# 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61d6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_unknown(df_x):\n",
    "    \"\"\"\n",
    "        Imputes unknown values to their mode\n",
    "    \"\"\"\n",
    "    x = df_x.copy()\n",
    "\n",
    "    marital_status_mode = x[\"marital_status\"].mode()[0]\n",
    "    x[\"marital_status\"] = x[\"marital_status\"].replace(\"Unknown\", marital_status_mode)\n",
    "    education_level_mode = x[\"education_level\"].mode()[0]\n",
    "    x[\"education_level\"] = x[\"education_level\"].replace(\"Unknown\", education_level_mode)\n",
    "    income_category_mode = x[\"income_category\"].mode()[0]\n",
    "    x[\"income_category\"] = x[\"income_category\"].replace(\"Unknown\", income_category_mode)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee8975b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df_x, df_y):\n",
    "    x = df_x.copy()\n",
    "    y = df_y.copy()\n",
    "    \n",
    "    # Encoding features with binary categories\n",
    "    label_enc = LabelEncoder()\n",
    "    y[\"attrition_flag\"] = label_enc.fit_transform(y[\"attrition_flag\"])\n",
    "    x[\"gender\"] = label_enc.fit_transform(x[\"gender\"])\n",
    "    \n",
    "    # Encoding features with multiple categories\n",
    "    onehot_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    values = onehot_enc.fit_transform(x[[\"marital_status\"]])\n",
    "    labels = np.array([\"divorced\", \"married\", \"single\"]).ravel()\n",
    "    marital_status_df = pd.DataFrame(values, columns=labels)\n",
    "\n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "    marital_status_df.reset_index(drop=True, inplace=True)\n",
    "    x = pd.concat([x, marital_status_df], axis=1)\n",
    "    x.drop(\"marital_status\", axis=1, inplace=True)\n",
    "    \n",
    "    # Encoding Ordinal Features\n",
    "    edu_level_mapper = {\"Doctorate\": 1, \"Post-Graduate\": 2, \"Graduate\": 3, \"College\": 4, \"High School\": 5, \"Uneducated\": 6}\n",
    "    x[\"education_level\"] = x[\"education_level\"].replace(edu_level_mapper)\n",
    "\n",
    "    income_cat_mapper = {\"$120K +\": 1, \"$80K - $120K\":2, \"$60K - $80K\":3, \"$40K - $60K\": 4, \"Less than $40K\": 5}\n",
    "    x[\"income_category\"] = x[\"income_category\"].replace(income_cat_mapper)\n",
    "\n",
    "    card_cat_mapper = {\"Platinum\":1, \"Gold\":2, \"Silver\":3, \"Blue\": 4}\n",
    "    x[\"card_category\"] = x[\"card_category\"].replace(card_cat_mapper)\n",
    "    \n",
    "    # Feature Transformation â€” Scaling\n",
    "    skewed = [\"credit_limit\", \"total_amt_change_q4_q1\", \"total_trans_amt\", \"total_count_change_q4_q1\"]\n",
    "\n",
    "    for skewed_col in skewed:\n",
    "#         x[skewed_col] = np.where(x[skewed_col] > 0 , np.log(x[skewed_col]), 0) # not using, leaving here for now\n",
    "        x[skewed_col] = np.log(x[skewed_col].mask(x[skewed_col] <=0)).fillna(0)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    x[numerical] = scaler.fit_transform(x[numerical]) \n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89953e5",
   "metadata": {},
   "source": [
    "### Execute preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c61dcc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning - imputing unknown\n",
    "x_train = impute_unknown(x_train)\n",
    "x_test = impute_unknown(x_test)\n",
    "\n",
    "# Dropping correlated features\n",
    "df = df.drop(columns=[\"customer_age\", \"avg_open_to_buy\", \"total_trans_count\"])\n",
    "\n",
    "# Feature engineering and feature scaling\n",
    "x_train, y_train = data_preprocessing(x_train, y_train)\n",
    "x_test, y_test = data_preprocessing(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a7dfa",
   "metadata": {},
   "source": [
    "# 5. Preprocessing Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02723b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_variation_model(x_train, y_train, x_test, y_test, variation):\n",
    "    if \"pca\" in variation:\n",
    "        pca = PCA(0.9, random_state=2021)\n",
    "        x_train = pca.fit_transform(x_train)\n",
    "        x_test = pca.fit_transform(x_test)\n",
    "        \n",
    "#     https://medium.com/analytics-vidhya/categorical-feature-selection-using-chi-squared-test-e4c0d0af6b7e\n",
    "#     https://towardsdatascience.com/using-the-chi-squared-test-for-feature-selection-with-implementation-b15a4dad93f1\n",
    "    if \"chi_square\" in variation:\n",
    "        chi_scores = chi2(x_train, y_train)\n",
    "        p_values = pd.Series(chi_scores[1], index = x_train.columns)\n",
    "        p_values.sort_values(ascending = False , inplace = True)\n",
    "#         p_values.plot.bar()\n",
    "        x_train = x_train.drop([\"card_category\", \"months_on_book\", \"divorced\", \"total_amt_change_q4_q1\", \"dependent_count\", \"single\", \"income_category\", \"married\", \"education_level\", \"credit_limit\", \"gender\"], axis=1)\n",
    "        x_test = x_test.drop([\"card_category\", \"months_on_book\", \"divorced\", \"total_amt_change_q4_q1\", \"dependent_count\", \"single\", \"income_category\", \"married\", \"education_level\", \"credit_limit\", \"gender\"], axis=1)\n",
    "        \n",
    "    if \"smote\" in variation:\n",
    "        oversampler = SMOTE(random_state=2021)\n",
    "        x_train, y_train = oversampler.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # Instantiate RandomClassifier, fit and predict\n",
    "    rf_clf = RandomForestClassifier(random_state=2021)\n",
    "    \n",
    "    rf_clf.fit(x_train, y_train.values.ravel() )\n",
    "    y_pred = rf_clf.predict(x_test)\n",
    "    \n",
    "    print(f\"-------------------------TEST SCORES for {variation}-----------------------\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"F2-Score: {fbeta_score(y_test, y_pred, beta=2)}\")\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"AUC Score: {roc_auc_score(y_test, y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0defa360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------TEST SCORES for base-----------------------\n",
      "Recall: 0.9876543209876543\n",
      "Precision: 0.9621993127147767\n",
      "F2-Score: 0.9824561403508772\n",
      "Accuracy score: 0.9570582428430404\n",
      "AUC Score: 0.8922886989553656\n",
      "\n",
      "-------------------------TEST SCORES for smote-----------------------\n",
      "Recall: 0.9717813051146384\n",
      "Precision: 0.9677985948477752\n",
      "F2-Score: 0.9709821428571428\n",
      "Accuracy score: 0.9491609081934848\n",
      "AUC Score: 0.9012752679419346\n",
      "\n",
      "-------------------------TEST SCORES for chi_square-----------------------\n",
      "Recall: 0.9829512051734274\n",
      "Precision: 0.9720930232558139\n",
      "F2-Score: 0.9807602064758331\n",
      "Accuracy score: 0.9619940769990128\n",
      "AUC Score: 0.91762944874056\n",
      "\n",
      "-------------------------TEST SCORES for pca-----------------------\n",
      "Recall: 0.9535567313345091\n",
      "Precision: 0.8559366754617415\n",
      "F2-Score: 0.9322910679388435\n",
      "Accuracy score: 0.8262586377097729\n",
      "AUC Score: 0.5567783656672546\n",
      "\n",
      "-------------------------TEST SCORES for smote, chi_square-----------------------\n",
      "Recall: 0.9653145208700764\n",
      "Precision: 0.9785458879618594\n",
      "F2-Score: 0.9679320914878565\n",
      "Accuracy score: 0.9531095755182626\n",
      "AUC Score: 0.9272726450504228\n",
      "\n",
      "-------------------------TEST SCORES for smote, pca-----------------------\n",
      "Recall: 0.8195179306290418\n",
      "Precision: 0.8696194635059263\n",
      "F2-Score: 0.829071012251695\n",
      "Accuracy score: 0.7453109575518263\n",
      "AUC Score: 0.5882205037760593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variations = [\"base\",\n",
    "              \"smote\",\n",
    "              \"chi_square\",\n",
    "              \"pca\",\n",
    "              \"smote, chi_square\",\n",
    "              \"smote, pca\"]\n",
    "\n",
    "for variation in variations:\n",
    "    run_variation_model(x_train, y_train, x_test, y_test, variation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da57ba6",
   "metadata": {},
   "source": [
    "# 6. Hyper paramter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15a03d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f0d87af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier__max_features [1, 5, 9, 13, 17]\n",
      "classifier__min_samples_leaf [1, 2, 4]\n",
      "classifier__n_estimators [100, 300, 500, 700, 900, 1100, 1300, 1500]\n",
      "classifier__max_depth [5, 10, 15, 20, 25, None]\n",
      "-----------------\n",
      "Total combinations: 720\n"
     ]
    }
   ],
   "source": [
    "# Creating parameter grid to search\n",
    "n_estimators = [ n for n in range(100, 1500+1, 200) ]\n",
    "\n",
    "max_depth = [ depth for depth in range(5, 30, 5) ]\n",
    "max_depth.append( None )\n",
    "\n",
    "max_features = list(range(1, x_train.shape[1], 4))\n",
    "\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "params_grid = {\n",
    "               'classifier__max_features': max_features,\n",
    "               'classifier__min_samples_leaf': min_samples_leaf,\n",
    "               'classifier__n_estimators': n_estimators,\n",
    "               'classifier__max_depth': max_depth\n",
    "              }\n",
    "\n",
    "total_combi = 1\n",
    "for param, value in params_grid.items():\n",
    "    print(param, value)\n",
    "    total_combi *= len(value)\n",
    "\n",
    "print('-----------------')\n",
    "print('Total combinations:', total_combi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d68f853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote_sampler = SMOTE(random_state=2021)\n",
    "# rf_clf = RandomForestClassifier(random_state=2021)\n",
    "\n",
    "# pipeline = Pipeline(steps = [['smote', smote_sampler],\n",
    "#                              ['classifier', rf_clf]])\n",
    "\n",
    "# stratified_kfold = StratifiedKFold(shuffle=True, n_splits=3, random_state=2021)\n",
    "\n",
    "# rf_gridsearch = RandomizedSearchCV(estimator = pipeline,\n",
    "#                            param_distributions = params_grid,\n",
    "#                            scoring = 'recall',\n",
    "#                            cv = stratified_kfold,\n",
    "#                            refit = True,\n",
    "#                            n_jobs = -1,\n",
    "#                            random_state = 2021)\n",
    "\n",
    "# rf_gridsearch.fit(x_train, y_train)\n",
    "\n",
    "# best_parameters = rf_gridsearch.best_params_\n",
    "# print(best_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
